<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Iterative INLA method â€¢ inlabru</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Iterative INLA method">
<meta property="og:description" content="inlabru">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">inlabru</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">2.4.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/linearapprox.html">Nonlinear model approximation</a>
    </li>
    <li>
      <a href="../articles/method.html">Iterative INLA method</a>
    </li>
    <li>
      <a href="../articles/web/1d_lgcp.html">LGCPs - An example in one dimension</a>
    </li>
    <li>
      <a href="../articles/web/2d_lgcp.html">LGCPs - An example in two dimensions</a>
    </li>
    <li>
      <a href="../articles/web/2d_lgcp_covars.html">LGCPs - Spatial covariates</a>
    </li>
    <li>
      <a href="../articles/web/2d_lgcp_distancesampling.html">LGCPs - Distance sampling</a>
    </li>
    <li>
      <a href="../articles/web/2d_lgcp_multilikelihood.html">LGCPs - Multiple Likelihoods</a>
    </li>
    <li>
      <a href="../articles/web/2d_lgcp_plotsampling.html">LGCPs - Plot sampling</a>
    </li>
    <li>
      <a href="../articles/web/2d_lgcp_spatiotemporal.html">LGCPs - An example in space and time</a>
    </li>
    <li>
      <a href="../articles/web/publications.html">Publications</a>
    </li>
    <li>
      <a href="../articles/web/random_fields.html">Random Fields in One Dimension</a>
    </li>
    <li>
      <a href="../articles/web/random_fields_2d.html">Random Fields in 2D</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/inlabru-org/inlabru/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="method_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Iterative INLA method</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/inlabru-org/inlabru/blob/HEAD/vignettes/method.Rmd" class="external-link"><code>vignettes/method.Rmd</code></a></small>
      <div class="hidden name"><code>method.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="the-inla-method-for-linear-predictors">The INLA method for linear predictors<a class="anchor" aria-label="anchor" href="#the-inla-method-for-linear-predictors"></a>
</h2>
<p>The INLA method is used to compute fast approximative posterior distribution for Bayesian generalised additive models. The hierarchical structure of such a model with latent Gaussian components <span class="math inline">\(\boldsymbol{u}\)</span>, covariance parameters <span class="math inline">\(\boldsymbol{\theta}\)</span>, and measured response variables <span class="math inline">\(\boldsymbol{y}\)</span>, can be written as <span class="math display">\[
\begin{aligned}
\boldsymbol{\theta} &amp;\sim p(\boldsymbol{\theta}) \\
\boldsymbol{u}|\boldsymbol{\theta} &amp;\sim \mathcal{N}\!\left(\boldsymbol{\mu}_u, \boldsymbol{Q}(\boldsymbol{\theta})^{-1}\right) \\
\boldsymbol{\eta}(\boldsymbol{u}) &amp;= \boldsymbol{A}\boldsymbol{u} \\
\boldsymbol{y}|\boldsymbol{u},\boldsymbol{\theta} &amp; \sim p(\boldsymbol{y}|\boldsymbol{\eta}(\boldsymbol{u}),\boldsymbol{\theta})
\end{aligned}
\]</span> where typically each linear predictor element, <span class="math inline">\(\eta_i(\boldsymbol{u})\)</span>, is linked to a location parameter of the distribution for observation <span class="math inline">\(y_i\)</span>, for each <span class="math inline">\(i\)</span>, via a (non-linear) link function <span class="math inline">\(g^{-1}(\cdot)\)</span>. In the R-INLA implementation, the observations are assumed to be conditionally independent, given <span class="math inline">\(\boldsymbol{\eta}\)</span> and <span class="math inline">\(\boldsymbol{\theta}\)</span>.</p>
</div>
<div class="section level2">
<h2 id="approximate-inla-for-non-linear-predictors">Approximate INLA for non-linear predictors<a class="anchor" aria-label="anchor" href="#approximate-inla-for-non-linear-predictors"></a>
</h2>
<p>The premise for the inlabru method for non-linear predictors is to build on the existing implementation, and only add a linearisation step. The properties of the resulting approximation will depend on the nature of the non-linearity.</p>
<p>Let <span class="math inline">\(\widetilde{\boldsymbol{\eta}}(\boldsymbol{u})\)</span> be a non-linear predictor, and let <span class="math inline">\(\overline{\boldsymbol{\eta}}(\boldsymbol{u})\)</span> be the 1st order Taylor approximation at <span class="math inline">\(\boldsymbol{u}_0\)</span>, <span class="math display">\[
\overline{\boldsymbol{\eta}}(\boldsymbol{u})
= \widetilde{\boldsymbol{\eta}}(\boldsymbol{u}_0) + \boldsymbol{B}(\boldsymbol{u} - \boldsymbol{u}_0)
= \left[\widetilde{\boldsymbol{\eta}}(\boldsymbol{u}_0) - \boldsymbol{B}\boldsymbol{u}_0\right] + \boldsymbol{B}\boldsymbol{u}
,
\]</span> where <span class="math inline">\(\boldsymbol{B}\)</span> is the derivative matrix for the non-linear predictor, evaluated at <span class="math inline">\(\boldsymbol{u}_0\)</span>.</p>
<p>The non-linear observation model <span class="math inline">\(p(\boldsymbol{y}|g^{-1}[\widetilde{\boldsymbol{\eta}}(\boldsymbol{u})],\boldsymbol{\theta})\)</span> is approximated by replacing the non-linear predictor with its linearisation, so that the linearised model is defined by <span class="math display">\[
\overline{p}(\boldsymbol{y}|\boldsymbol{u},\boldsymbol{\theta})
=
p(\boldsymbol{y}|\overline{\boldsymbol{\eta}}(\boldsymbol{u}),\boldsymbol{\theta})
=
p(\boldsymbol{y}|g^{-1}[\overline{\boldsymbol{\eta}}(\boldsymbol{u})],\boldsymbol{\theta})
\approx
p(\boldsymbol{y}|g^{-1}[\widetilde{\boldsymbol{\eta}}(\boldsymbol{u})],\boldsymbol{\theta})
=
p(\boldsymbol{y}|\widetilde{\boldsymbol{\eta}}(\boldsymbol{u}),\boldsymbol{\theta})
=
\widetilde{p}(\boldsymbol{y}|\boldsymbol{u},\boldsymbol{\theta})
\]</span> The non-linear model posterior is factorised as <span class="math display">\[
\widetilde{p}(\boldsymbol{\theta},\boldsymbol{u}|\boldsymbol{y}) = \widetilde{p}(\boldsymbol{\theta}|\boldsymbol{y})\widetilde{p}(\boldsymbol{u}|\boldsymbol{y},\boldsymbol{\theta}),
\]</span> and the linear model approximation is factorised as <span class="math display">\[
\overline{p}(\boldsymbol{\theta},\boldsymbol{u}|\boldsymbol{y}) = \overline{p}(\boldsymbol{\theta}|\boldsymbol{y})\overline{p}(\boldsymbol{u}|\boldsymbol{y},\boldsymbol{\theta}) .
\]</span></p>
<div class="section level3">
<h3 id="fixed-point-iteration">Fixed point iteration<a class="anchor" aria-label="anchor" href="#fixed-point-iteration"></a>
</h3>
<p>The remaining step of the approximation is how to choose the linearisation point <span class="math inline">\(\boldsymbol{u}_0\)</span>. We start by introducing a functional <span class="math inline">\(f(\overline{p}_{\boldsymbol{v}})\)</span> of the posterior distribution linearised at <span class="math inline">\(\boldsymbol{v}\)</span>, that generates a latent field configuration. We then seek a fix point of the functional, so that <span class="math inline">\(\boldsymbol{u}_0=f(\overline{p}_{\boldsymbol{u}_0})\)</span>. Potential choices for <span class="math inline">\(f(\cdot)\)</span> include the posterior expectation <span class="math inline">\(\overline{E}(\boldsymbol{u}|\boldsymbol{y})\)</span> and the joint conditional mode, <span class="math display">\[
f(\overline{p}_{\boldsymbol{v}})=\mathop{\mathrm{arg\,max}}_{\boldsymbol{u}} \overline{p}_{\boldsymbol{v}}(\boldsymbol{u}|\boldsymbol{y},\widehat{\boldsymbol{\theta}}),
\]</span> where <span class="math inline">\(\widehat{\boldsymbol{\theta}}=\mathop{\mathrm{arg\,max}}_{\boldsymbol{\theta}} \overline{p}_{\boldsymbol{v}}(\boldsymbol{\theta}|\boldsymbol{y})\)</span> (used in <code>inlabru</code> from version 2.2.3<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>) One key to the fix point iteration is that the observation model is linked to <span class="math inline">\(\boldsymbol{u}\)</span> only through the non-linear predictor <span class="math inline">\(\widetilde{\boldsymbol{\eta}}(\boldsymbol{u})\)</span>.</p>
<ol start="0" style="list-style-type: decimal">
<li>Let <span class="math inline">\(\boldsymbol{u}_0\)</span> be an initial linearisation point for the latent variables.</li>
<li>Compute the predictor linearisation at <span class="math inline">\(\boldsymbol{u}_0\)</span>,</li>
<li>Compute the linearised INLA posterior <span class="math inline">\(\overline{p}(\boldsymbol{\theta}|\boldsymbol{y})\)</span>
</li>
<li>Let <span class="math inline">\(\boldsymbol{u}_1=f(\overline{p}_{\boldsymbol{u}_0})\)</span> be the initial candidate for new linearisation point.</li>
<li>Let <span class="math inline">\(\boldsymbol{u}_\alpha=(1-\alpha)\boldsymbol{u}_0+\alpha\boldsymbol{u}_1\)</span>, and find the value <span class="math inline">\(\alpha\)</span> that minimises <span class="math inline">\(\|\widetilde{\eta}(\boldsymbol{u}_\alpha)-\overline{\eta}(\boldsymbol{u}_1)\|\)</span>.</li>
<li>Set the linearisation point equal to <span class="math inline">\(\boldsymbol{u}_\alpha\)</span> and repeat from step 1, unless the iteration has converged to a given tolerance.</li>
</ol>
<div class="section level4">
<h4 id="line-search">Line search<a class="anchor" aria-label="anchor" href="#line-search"></a>
</h4>
<p>In step 4, an approximate line search can be used, that avoids many potentially expensive evaluations of the non-linear predictor. We evaluate <span class="math inline">\(\widetilde{\boldsymbol{\eta}}_1=\widetilde{\boldsymbol{\eta}}(\boldsymbol{u}_1)\)</span> and make use of the linearised predictor information. Let <span class="math inline">\(\widetilde{\boldsymbol{\eta}}_\alpha=\widetilde{\boldsymbol{\eta}}(\boldsymbol{u}_\alpha)\)</span> and <span class="math inline">\(\overline{\boldsymbol{\eta}}_\alpha=\overline{\boldsymbol{\eta}}(\boldsymbol{u}_\alpha)=(1-\alpha)\widetilde{\boldsymbol{\eta}}(\boldsymbol{u}_0)+\alpha\overline{\boldsymbol{\eta}}(\boldsymbol{u}_1)\)</span>. An exact line search would minimise <span class="math inline">\(\|\widetilde{\boldsymbol{\eta}}_\alpha-\overline{\boldsymbol{\eta}}_1\|\)</span>. Instead, we define a quadratic approximation to the non-linear predictor as a function of <span class="math inline">\(\alpha\)</span>, <span class="math display">\[
\breve{\boldsymbol{\eta}}_\alpha =
\overline{\boldsymbol{\eta}}_\alpha + \alpha^2 (\widetilde{\boldsymbol{\eta}}_1 - \overline{\boldsymbol{\eta}}_1)
\]</span> and minimise the quartic polynomial in <span class="math inline">\(\alpha\)</span>, <span class="math display">\[
\begin{aligned}
\|\breve{\boldsymbol{\eta}}_\alpha-\overline{\boldsymbol{\eta}}_1\|^2
&amp;=
\| (\alpha-1)(\overline{\boldsymbol{\eta}}_1 - \overline{\boldsymbol{\eta}}_0) + \alpha^2 (\widetilde{\boldsymbol{\eta}}_1 - \overline{\boldsymbol{\eta}}_1) \|^2
.
\end{aligned}
\]</span> If initial expansion and contraction steps are carried out, leading to an initial guess of <span class="math inline">\(\alpha=\gamma^k\)</span>, where <span class="math inline">\(\gamma&gt;1\)</span> is a scaling factor (see <code><a href="../reference/bru_options.html">?bru_options</a></code>, <code>bru_method$factor</code>) and <span class="math inline">\(k\)</span> is the (signed) number of expansions and contractions, the quadratic expression is replaced by <span class="math display">\[
\begin{aligned}
\|\breve{\boldsymbol{\eta}}_\alpha-\overline{\boldsymbol{\eta}}_1\|^2
&amp;=
\| (\alpha-1)(\overline{\boldsymbol{\eta}}_1 - \overline{\boldsymbol{\eta}}_0) + \frac{\alpha^2}{\gamma^{2k}} (\widetilde{\boldsymbol{\eta}}_{\gamma^k} - \overline{\boldsymbol{\eta}}_{\gamma^k}) \|^2
,
\end{aligned}
\]</span> which is minimised on the interval <span class="math inline">\(\alpha\in[\gamma^{k-1},\gamma^{k+1}]\)</span>.</p>
<p>A potential improvement of step 4 might be to also take into account the prior distribution for <span class="math inline">\(\boldsymbol{u}\)</span> as a minimisation penalty, to avoid moving further than would be indicated by a full likelihood optimisation.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p> Note: In <code>inlabru</code> version 2.1.15, <span class="math display">\[
f(\overline{p}_{\boldsymbol{v}})=\left\{\mathop{\mathrm{arg\,max}}_{u_i} \overline{p}_{\boldsymbol{v}}(u_i|\boldsymbol{y}),\,i=1,\dots,n\right\},
\]</span> was used, which caused problems for some nonlinear models.<a href="#fnref1" class="footnote-back">â†©ï¸Ž</a></p></li>
</ol>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Finn Lindgren, Fabian E. Bachl.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.2.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
